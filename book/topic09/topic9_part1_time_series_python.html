

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Topic 9. Part 1. Time series analysis in Python &#8212; mlcourse.ai</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://c6.patreon.com/becomePatronButton.bundle.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-CN7ZN59CQB"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-CN7ZN59CQB');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/topic09/topic9_part1_time_series_python';</script>
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Topic 9. Time series analysis in Python. Part 2. Predicting the future with Facebook Prophet" href="topic9_part2_facebook_prophet.html" />
    <link rel="prev" title="Topic 9. Time Series Analysis with Python" href="topic09_intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/mlcourse_ai_logo.jpg" class="logo__image only-light" alt="mlcourse.ai - Home"/>
    <script>document.write(`<img src="../../_static/mlcourse_ai_logo.jpg" class="logo__image only-dark" alt="mlcourse.ai - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Intro
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Prerequisites</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../prereqs/python.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prereqs/math.html">Math</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prereqs/software_devops.html">Software &amp; DevOps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prereqs/docker.html">Docker</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic01/topic01_intro.html">Topic 1 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic01/topic01_pandas_data_analysis.html">Exploratory data analysis with Pandas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic01/videolecture01.html">Videolecture 1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic01/assignment01_pandas_uci_adult.html">Demo Assignment 1 Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic01/assignment01_pandas_uci_adult_solution.html">Demo Assignment 1 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic01/bonus_assignment01_pandas_olympics.html">Bonus Assignment 1</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic02/topic02_intro.html">Topic 2 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic02/topic02_visual_data_analysis.html">Visual Data Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic02/topic02_additional_seaborn_matplotlib_plotly.html">Seaborn, Matplotlib, Plotly</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic02/videolecture02.html">Videolecture 2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic02/assignment02_analyzing_cardiovascular_desease_data.html">Demo Assignment 2 Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic02/assignment02_analyzing_cardiovascular_desease_data_solution.html">Demo Assignment 2 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic02/bonus_assignment02_visual_analysis.html">Bonus Assignment 2</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic03/topic03_intro.html">Topic 3 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic03/topic03_decision_trees_kNN.html">Classification, Decision Trees &amp; k Nearest Neighbors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic03/videolecture03.html">Videolecture 3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic03/assignment03_decision_trees.html">Demo Assignment 3 Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic03/assignment03_decision_trees_solution.html">Demo Assignment 3 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic03/bonus_assignment03_decision_trees.html">Bonus Assignment 3</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic04/topic04_intro.html">Topic 4 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/topic4_linear_models_part1_mse_likelihood_bias_variance.html">Ordinary Least Squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/topic4_linear_models_part2_logit_likelihood_learning.html">Linear classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/topic4_linear_models_part3_regul_example.html">An illustrative example of logistic regression regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/topic4_linear_models_part4_good_bad_logit_movie_reviews_XOR.html">When logistic regression is good and when it is not</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/topic4_linear_models_part5_valid_learning_curves.html">Validation and learning curves</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/videolecture04.html">Videolecture 4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/assignment04_regression_wine.html">Demo Assignment 4 Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/assignment04_regression_wine_solution.html">Demo Assignment 4 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic04/bonus_assignment04_alice_baselines.html">Bonus Assignment 4</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic05/topic05_intro.html">Topic 5 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic05/topic5_part1_bagging.html">Bagging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic05/topic5_part2_random_forest.html">Random Forest</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic05/topic5_part3_feature_importance.html">Feature importance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic05/videolecture05.html">Videolecture 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic05/assignment05_logit_rf_credit_scoring.html">Demo Assignment 5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic05/assignment05_logit_rf_credit_scoring_solution.html">Demo Assignment 5 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic05/bonus_assignment05_logreg_rf.html">Bonus Assignment 5</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic06/topic06_intro.html">Topic 6 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic06/topic6_feature_engineering_feature_selection.html">Feature engineering &amp; feature selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic06/demo_assignment06.html">Demo Assignment 6 Task</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic06/bonus_assignment06.html">Bonus Assignment 6</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 7</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic07/topic07_intro.html">Topic 7 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic07/topic7_pca_clustering.html">Unsupervised learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic07/videolecture07.html">Videolecture 7</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic07/assignment07_unsupervised_learning.html">Demo Assignment 7</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic07/assignment07_unsupervised_learning_solution.html">Demo Assignment 7 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic07/bonus_assignment07.html">Bonus Assignment 7</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 8</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic08/topic08_intro.html">Topic 8 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic08/topic08_sgd_hashing_vowpal_wabbit.html">Vowpal Wabbit: Learning with Gigabytes of Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic08/videolecture08.html">Videolecture 8</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic08/assignment08_implement_sgd_regressor.html">Demo Assignment 8</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic08/assignment08_implement_sgd_regressor_solution.html">Demo Assignment 8 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic08/bonus_assignment08.html">Bonus Assignment 8</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 9</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="topic09_intro.html">Topic 9 Intro</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Topic 9. Part 1. Time series analysis in Python</a></li>







<li class="toctree-l1"><a class="reference internal" href="topic9_part2_facebook_prophet.html">Predicting the future with Facebook Prophet</a></li>
<li class="toctree-l1"><a class="reference internal" href="videolecture09.html">Videolecture 9</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignment09_time_series.html">Demo Assignment 9</a></li>
<li class="toctree-l1"><a class="reference internal" href="assignment09_time_series_solution.html">Demo Assignment 9 Solution</a></li>
<li class="toctree-l1"><a class="reference internal" href="bonus_assignment09.html">Bonus Assignment 9</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Topic 10</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../topic10/topic10_intro.html">Topic 10 Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic10/topic10_gradient_boosting.html">Gradient boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic10/videolecture10.html">Videolecture 10</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic10/assignment10_flight_delays_kaggle.html">Demo Assignment 10</a></li>
<li class="toctree-l1"><a class="reference internal" href="../topic10/bonus_assignment10.html">Bonus Assignment 10</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About the course</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../extra/tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extra/rating.html">Rating</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extra/resources.html">Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extra/contributors.html">Contributors</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Yorko/mlcourse.ai" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Yorko/mlcourse.ai/edit/main/mlcourse_ai_jupyter_book/book/topic09/topic9_part1_time_series_python.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Yorko/mlcourse.ai/issues/new?title=Issue%20on%20page%20%2Fbook/topic09/topic9_part1_time_series_python.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/book/topic09/topic9_part1_time_series_python.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Topic 9. Part 1. Time series analysis in Python</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Topic 9. Part 1. Time series analysis in Python</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#article-outline">Article outline</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forecast-quality-metrics">Forecast quality metrics</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#move-smoothe-evaluate">Move, smoothe, evaluate</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exponential-smoothing">Exponential smoothing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#double-exponential-smoothing">Double exponential smoothing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#triple-exponential-smoothing-a-k-a-holt-winters">Triple exponential smoothing a.k.a. Holt-Winters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-cross-validation">Time series cross validation</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#econometric-approach">Econometric approach</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationarity">Stationarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-rid-of-non-stationarity-and-building-sarima">Getting rid of non-stationarity and building SARIMA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arima-family-crash-course">ARIMA-family Crash-Course</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-and-not-only-models-for-time-series">Linear (and not only) models for time series</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">Feature extraction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-lags">Time series lags</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#target-encoding">Target encoding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-and-feature-selection">Regularization and feature selection</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#boosting">Boosting</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#useful-resources">Useful resources</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="topic-9-part-1-time-series-analysis-in-python">
<span id="topic09-part1"></span><h1><a class="toc-backref" href="#id1" role="doc-backlink">Topic 9. Part 1. Time series analysis in Python</a><a class="headerlink" href="#topic-9-part-1-time-series-analysis-in-python" title="Permalink to this heading">#</a></h1>
<img src="https://habrastorage.org/webt/ia/m9/zk/iam9zkyzqebnf_okxipihkgjwnw.jpeg" />
<p><strong><center><a class="reference external" href="https://mlcourse.ai">mlcourse.ai</a> – Open Machine Learning Course</strong> </center><br></p>
<p>Author: <a class="reference external" href="https://github.com/DmitrySerg">Dmitriy Sergeyev</a>, Data Scientist &#64; Zeptolab, lecturer in the Center of Mathematical Finance in MSU. Translated by: &#64;borowis. This material is subject to the terms and conditions of the <a class="reference external" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons CC BY-NC-SA 4.0</a> license. Free use is permitted for any non-commercial purpose.</p>
<p>We continue our open machine learning course with a new article on time series.</p>
<p>Let’s take a look at how to work with time series in Python: what methods and models we can use for prediction, what double and triple exponential smoothing is, what to do if stationarity is not your favorite thing, how to build SARIMA and stay alive, how to make predictions using xgboost… In addition, all of this will be applied to (harsh) real world examples.</p>
<section id="article-outline">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">Article outline</a><a class="headerlink" href="#article-outline" title="Permalink to this heading">#</a></h2>
<nav class="contents" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#topic-9-part-1-time-series-analysis-in-python" id="id1">Topic 9. Part 1. Time series analysis in Python</a></p>
<ul>
<li><p><a class="reference internal" href="#article-outline" id="id2">Article outline</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#introduction" id="id3">Introduction</a></p>
<ul>
<li><p><a class="reference internal" href="#forecast-quality-metrics" id="id4">Forecast quality metrics</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#move-smoothe-evaluate" id="id5">Move, smoothe, evaluate</a></p>
<ul>
<li><p><a class="reference internal" href="#exponential-smoothing" id="id6">Exponential smoothing</a></p></li>
<li><p><a class="reference internal" href="#double-exponential-smoothing" id="id7">Double exponential smoothing</a></p></li>
<li><p><a class="reference internal" href="#triple-exponential-smoothing-a-k-a-holt-winters" id="id8">Triple exponential smoothing a.k.a. Holt-Winters</a></p></li>
<li><p><a class="reference internal" href="#time-series-cross-validation" id="id9">Time series cross validation</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#econometric-approach" id="id10">Econometric approach</a></p>
<ul>
<li><p><a class="reference internal" href="#stationarity" id="id11">Stationarity</a></p></li>
<li><p><a class="reference internal" href="#getting-rid-of-non-stationarity-and-building-sarima" id="id12">Getting rid of non-stationarity and building SARIMA</a></p></li>
<li><p><a class="reference internal" href="#arima-family-crash-course" id="id13">ARIMA-family Crash-Course</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#linear-and-not-only-models-for-time-series" id="id14">Linear (and not only) models for time series</a></p>
<ul>
<li><p><a class="reference internal" href="#feature-extraction" id="id15">Feature extraction</a></p></li>
<li><p><a class="reference internal" href="#time-series-lags" id="id16">Time series lags</a></p></li>
<li><p><a class="reference internal" href="#target-encoding" id="id17">Target encoding</a></p></li>
<li><p><a class="reference internal" href="#regularization-and-feature-selection" id="id18">Regularization and feature selection</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#boosting" id="id19">Boosting</a></p></li>
<li><p><a class="reference internal" href="#conclusion" id="id20">Conclusion</a></p></li>
<li><p><a class="reference internal" href="#useful-resources" id="id21">Useful resources</a></p></li>
</ul>
</nav>
<p>In my day-to-day job, I encounter time-series related tasks almost every day. The most frequent questions asked are the following: what will happen with our metrics in the next day/week/month/etc., how many users will install our app, how much time will they spend online, how many actions will users complete, and so on. We can approach these prediction tasks using different methods depending on the required quality of the prediction, length of the forecast period, and, of course, the time within which we have to choose features and tune parameters to achieve desired results.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="introduction">
<h1><a class="toc-backref" href="#id3" role="doc-backlink">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this heading">#</a></h1>
<p>We begin with a simple <a class="reference external" href="https://en.wikipedia.org/wiki/Time_series">definition</a> of time series:</p>
<blockquote>
<div><p><em>Time series</em> is a series of data points indexed (or listed or graphed) in time order.</p>
</div></blockquote>
<p>Therefore, the data is organized by relatively deterministic timestamps, and may, compared to random sample data, contain additional information that we can extract.</p>
<p>Let’s import some libraries. First, we will need the <a class="reference external" href="http://statsmodels.sourceforge.net/stable/">statsmodels</a> library, which has many statistical modeling functions, including time series. For R aficionados who had to move to Python, <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> will definitely look more familiar since it supports model definitions like ‘Wage ~ Age + Education’.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  <span class="c1"># plots</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  <span class="c1"># vectors and matrices</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>  <span class="c1"># tables and data manipulations</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>  <span class="c1"># more plots</span>

<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>

<span class="kn">import</span> <span class="nn">warnings</span>  
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">product</span>  <span class="c1"># some useful functions</span>

<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">scs</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>  <span class="c1"># statistics and econometrics</span>
<span class="kn">import</span> <span class="nn">statsmodels.tsa.api</span> <span class="k">as</span> <span class="nn">smt</span>
<span class="kn">from</span> <span class="nn">dateutil.relativedelta</span> <span class="kn">import</span> \
    <span class="n">relativedelta</span>  <span class="c1"># working with dates with style</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>  <span class="c1"># for function minimization</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span> <span class="c1"># `do not disturbe` mode</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;
</pre></div>
</div>
</div>
</div>
<p>As an example, let’s look at real mobile game data. Specifically, we will look into ads watched per hour and in-game currency spend per day:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># for Jupyter-book, we copy data from GitHub, locally, to save Internet traffic,</span>
<span class="c1"># you can specify the data/ folder from the root of your cloned</span>
<span class="c1"># https://github.com/Yorko/mlcourse.ai repo, to save Internet traffic</span>
<span class="n">DATA_PATH</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/Yorko/mlcourse.ai/main/data/&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ads</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_PATH</span> <span class="o">+</span> <span class="s2">&quot;ads.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">],</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">])</span>
<span class="n">currency</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span> <span class="o">+</span> <span class="s2">&quot;currency.csv&quot;</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">],</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Time&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Ads watched (hourly data)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/5d95bc33ed82109a71b7b4dd20368385d23a97f1a6fa0f5c8741363ade1dcacb.png" src="../../_images/5d95bc33ed82109a71b7b4dd20368385d23a97f1a6fa0f5c8741363ade1dcacb.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">currency</span><span class="o">.</span><span class="n">GEMS_GEMS_SPENT</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;In-game currency spent (daily data)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a28acb75ee81c68902a2aae6972ad847e2721c4b26aeec17080cfa02396a8b0d.png" src="../../_images/a28acb75ee81c68902a2aae6972ad847e2721c4b26aeec17080cfa02396a8b0d.png" />
</div>
</div>
<section id="forecast-quality-metrics">
<h2><a class="toc-backref" href="#id4" role="doc-backlink">Forecast quality metrics</a><a class="headerlink" href="#forecast-quality-metrics" title="Permalink to this heading">#</a></h2>
<p>Before we begin forecasting, let’s understand how to measure the quality of our predictions and take a look at the most commonly used metrics.</p>
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/model_evaluation.html#r2-score-the-coefficient-of-determination">R squared</a>: coefficient of determination (in econometrics, this can be interpreted as the percentage of variance explained by the model), <span class="math notranslate nohighlight">\((-\infty, 1]\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(R^2 = 1 - \frac{SS_{res}}{SS_{tot}}\)</span></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">r2_score</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error">Mean Absolute Error</a>: this is an interpretable metric because it has the same unit of measurement as the initial series, <span class="math notranslate nohighlight">\([0, +\infty)\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(MAE = \frac{\sum\limits_{i=1}^{n} |y_i - \hat{y}_i|}{n}\)</span></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_absolute_error</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/model_evaluation.html#median-absolute-error">Median Absolute Error</a>: again, an interpretable metric that is particularly interesting because it is robust to outliers, <span class="math notranslate nohighlight">\([0, +\infty)\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(MedAE = median(|y_1 - \hat{y}_1|, ... , |y_n - \hat{y}_n|)\)</span></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">median_absolute_error</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-error">Mean Squared Error</a>: the most commonly used metric that gives a higher penalty to large errors and vice versa, <span class="math notranslate nohighlight">\([0, +\infty)\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(MSE = \frac{1}{n}\sum\limits_{i=1}^{n} (y_i - \hat{y}_i)^2\)</span></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_error</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/model_evaluation.html#mean-squared-logarithmic-error">Mean Squared Logarithmic Error</a>: practically, this is the same as MSE, but we take the logarithm of the series. As a result, we give more weight to small mistakes as well. This is usually used when the data has exponential trends, <span class="math notranslate nohighlight">\([0, +\infty)\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(MSLE = \frac{1}{n}\sum\limits_{i=1}^{n} (log(1+y_i) - log(1+\hat{y}_i))^2\)</span></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sklearn</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">mean_squared_log_error</span>
</pre></div>
</div>
<hr class="docutils" />
<ul class="simple">
<li><p>Mean Absolute Percentage Error: this is the same as MAE but is computed as a percentage, which is very convenient when you want to explain the quality of the model to management, <span class="math notranslate nohighlight">\([0, +\infty)\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(MAPE = \frac{100}{n}\sum\limits_{i=1}^{n} \frac{|y_i - \hat{y}_i|}{y_i}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_true</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Importing everything from above</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span>
                             <span class="n">mean_squared_log_error</span><span class="p">,</span> <span class="n">median_absolute_error</span><span class="p">,</span>
                             <span class="n">r2_score</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">/</span> <span class="n">y_true</span><span class="p">))</span> <span class="o">*</span> <span class="mi">100</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You should be very careful with MAPE, MSLE and other metrics that are poorly defined around <span class="math notranslate nohighlight">\(y=0\)</span>. Formally, MAPE is not defined for any <span class="math notranslate nohighlight">\(y_i = 0\)</span>. In practice, these metric can “explode” even for small values of <span class="math notranslate nohighlight">\(y_i\)</span> around 0. The ways to go around this limitation should be clear for the end user. For example, simply ignoring actual values <span class="math notranslate nohighlight">\(y_i = 0\)</span> is indeed a workaround but a bad one: thus, we’d ignore those cases where the prediction is high (<span class="math notranslate nohighlight">\(\hat{y}_i \gg 1\)</span>) and the actual value is 0 (<span class="math notranslate nohighlight">\(y_i = 0\)</span>). More of this is <a class="reference external" href="https://stats.stackexchange.com/questions/299712/what-are-the-shortcomings-of-the-mean-absolute-percentage-error-mape">discussed</a> on CrossValidated.</p>
</div>
<p>Now that we know how to measure the quality of the forecasts, let’s see what metrics we can use and how to translate the results for the boss. After that, one small detail remains - building the model.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="move-smoothe-evaluate">
<h1><a class="toc-backref" href="#id5" role="doc-backlink">Move, smoothe, evaluate</a><a class="headerlink" href="#move-smoothe-evaluate" title="Permalink to this heading">#</a></h1>
<p>Let’s start with a naive hypothesis: “tomorrow will be the same as today”. However, instead of a model like <span class="math notranslate nohighlight">\(\hat{y}_{t} = y_{t-1}\)</span> (which is actually a great baseline for any time series prediction problems and sometimes is impossible to beat), we will assume that the future value of our variable depends on the average of its <span class="math notranslate nohighlight">\(k\)</span> previous values. Therefore, we will use the <strong>moving average</strong>.</p>
<p><span class="math notranslate nohighlight">\(\hat{y}_{t} = \frac{1}{k} \displaystyle\sum^{k}_{n=1} y_{t-n}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">moving_average</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate average of last n observations</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="o">-</span><span class="n">n</span><span class="p">:])</span>


<span class="n">moving_average</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>  <span class="c1"># prediction for the last observed day (past 24 hours)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.float64(116805.0)
</pre></div>
</div>
</div>
</div>
<p>Unfortunately, we cannot make predictions far in the future - in order to get the value for the next step, we need the previous values to be actually observed. But moving average has another use case - smoothing the original time series to identify trends. Pandas has an implementation available with <a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.rolling.html"><code class="docutils literal notranslate"><span class="pre">DataFrame.rolling(window).mean()</span></code></a>. The wider the window, the smoother the trend. In the case of very noisy data, which is often encountered in finance, this procedure can help detect common patterns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotMovingAverage</span><span class="p">(</span>
    <span class="n">series</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.96</span><span class="p">,</span> <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        series - dataframe with timeseries</span>
<span class="sd">        window - rolling window size</span>
<span class="sd">        plot_intervals - show confidence intervals</span>
<span class="sd">        plot_anomalies - show anomalies</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rolling_mean</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="n">window</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Moving average</span><span class="se">\n</span><span class="s2"> window size = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">window</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rolling_mean</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Rolling mean trend&quot;</span><span class="p">)</span>

    <span class="c1"># Plot confidence intervals for smoothed values</span>
    <span class="k">if</span> <span class="n">plot_intervals</span><span class="p">:</span>
        <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="n">window</span><span class="p">:],</span> <span class="n">rolling_mean</span><span class="p">[</span><span class="n">window</span><span class="p">:])</span>
        <span class="n">deviation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="n">window</span><span class="p">:]</span> <span class="o">-</span> <span class="n">rolling_mean</span><span class="p">[</span><span class="n">window</span><span class="p">:])</span>
        <span class="n">lower_bond</span> <span class="o">=</span> <span class="n">rolling_mean</span> <span class="o">-</span> <span class="p">(</span><span class="n">mae</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">deviation</span><span class="p">)</span>
        <span class="n">upper_bond</span> <span class="o">=</span> <span class="n">rolling_mean</span> <span class="o">+</span> <span class="p">(</span><span class="n">mae</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">deviation</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">upper_bond</span><span class="p">,</span> <span class="s2">&quot;r--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Upper Bond / Lower Bond&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lower_bond</span><span class="p">,</span> <span class="s2">&quot;r--&quot;</span><span class="p">)</span>

        <span class="c1"># Having the intervals, find abnormal values</span>
        <span class="k">if</span> <span class="n">plot_anomalies</span><span class="p">:</span>
            <span class="n">anomalies</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">series</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">series</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
            <span class="n">anomalies</span><span class="p">[</span><span class="n">series</span> <span class="o">&lt;</span> <span class="n">lower_bond</span><span class="p">]</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="n">series</span> <span class="o">&lt;</span> <span class="n">lower_bond</span><span class="p">]</span>
            <span class="n">anomalies</span><span class="p">[</span><span class="n">series</span> <span class="o">&gt;</span> <span class="n">upper_bond</span><span class="p">]</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="n">series</span> <span class="o">&gt;</span> <span class="n">upper_bond</span><span class="p">]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">anomalies</span><span class="p">,</span> <span class="s2">&quot;ro&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">series</span><span class="p">[</span><span class="n">window</span><span class="p">:],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Actual values&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper left&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s smooth by the previous 4 hours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotMovingAverage</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ec74d35e747f52dcf73c2ccabbb0354cbcf76c0b57f075b6dfa957667502039b.png" src="../../_images/ec74d35e747f52dcf73c2ccabbb0354cbcf76c0b57f075b6dfa957667502039b.png" />
</div>
</div>
<p>Now let’s try smoothing by the previous 12 hours.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotMovingAverage</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/328e4a3861f714ebd63e7098e1bc6a36948734b8b8d37473ddcfcfde0bb0a5e7.png" src="../../_images/328e4a3861f714ebd63e7098e1bc6a36948734b8b8d37473ddcfcfde0bb0a5e7.png" />
</div>
</div>
<p>Now smoothing with the previous 24 hours, we get the daily trend.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotMovingAverage</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/b061c9cf8701aa03ef3f025b636cb32297262283942a19b2d7a74002075da644.png" src="../../_images/b061c9cf8701aa03ef3f025b636cb32297262283942a19b2d7a74002075da644.png" />
</div>
</div>
<p>When we applied daily smoothing on hourly data, we could clearly see the dynamics of ads watched. During the weekends, the values are higher (more time to play on the weekends) while fewer ads are watched on weekdays.</p>
<p>We can also plot confidence intervals for our smoothed values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotMovingAverage</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/93a9132f0bab4275d1f08b9cf5ce02358efc813ba0a2da3a54c07bf00a130b60.png" src="../../_images/93a9132f0bab4275d1f08b9cf5ce02358efc813ba0a2da3a54c07bf00a130b60.png" />
</div>
</div>
<p>Now, let’s create a simple anomaly detection system with the help of moving average. Unfortunately, in this particular dataset, everything is more or less normal, so we will intentionally make one of the values abnormal in our dataframe <code class="docutils literal notranslate"><span class="pre">ads_anomaly</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ads_anomaly</span> <span class="o">=</span> <span class="n">ads</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">ads_anomaly</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">]</span> <span class="o">=</span> <span class="n">ads_anomaly</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.2</span>  <span class="c1"># say we have 80% drop of ads</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see if this simple method can catch the anomaly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotMovingAverage</span><span class="p">(</span><span class="n">ads_anomaly</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/3e1740d5cc1ccbb53f800992bcda06b6bcef859477c3051cdb27d615910438ef.png" src="../../_images/3e1740d5cc1ccbb53f800992bcda06b6bcef859477c3051cdb27d615910438ef.png" />
</div>
</div>
<p>Neat! What about the second series?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotMovingAverage</span><span class="p">(</span>
    <span class="n">currency</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>  <span class="c1"># weekly smoothing</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/2650478f156e656fc29c06e5b9a9c4459187b547a4f543335f72e841b2b32729.png" src="../../_images/2650478f156e656fc29c06e5b9a9c4459187b547a4f543335f72e841b2b32729.png" />
</div>
</div>
<p>Oh no, this was not as great! Here, we can see the downside of our simple approach – it did not capture the monthly seasonality in our data and marked almost all 30-day peaks as anomalies. If you want to avoid false positives, it is best to consider more complex models.</p>
<p><strong>Weighted average</strong> is a simple modification to the moving average. The weights sum up to <code class="docutils literal notranslate"><span class="pre">1</span></code> with larger weights assigned to more recent observations.</p>
<p><span class="math notranslate nohighlight">\(\hat{y}_{t} = \displaystyle\sum^{k}_{n=1} \omega_n y_{t+1-n}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">weighted_average</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculate weighted average on the series.</span>
<span class="sd">        Assuming weights are sorted in descending order</span>
<span class="sd">        (larger weights are assigned to more recent observations).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)):</span>
        <span class="n">result</span> <span class="o">+=</span> <span class="n">series</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">weights</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weighted_average</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>87025.5
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># just checking</span>
<span class="mf">0.6</span> <span class="o">*</span> <span class="n">ads</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">ads</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">ads</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ads    87025.5
dtype: float64
</pre></div>
</div>
</div>
</div>
<section id="exponential-smoothing">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Exponential smoothing</a><a class="headerlink" href="#exponential-smoothing" title="Permalink to this heading">#</a></h2>
<p>Now, let’s see what happens if, instead of weighting the last <span class="math notranslate nohighlight">\(k\)</span> values of the time series, we start weighting all available observations while exponentially decreasing the weights as we move further back in time. There exists a formula for <strong><a class="reference external" href="https://en.wikipedia.org/wiki/Exponential_smoothing">exponential smoothing</a></strong> that will help us with this:</p>
<div class="math notranslate nohighlight">
\[\hat{y}_{t} = \alpha \cdot y_t + (1-\alpha) \cdot \hat y_{t-1} \]</div>
<p>Here the model value is a weighted average between the current true value and the previous model values. The <span class="math notranslate nohighlight">\(\alpha\)</span> weight is called a smoothing factor. It defines how quickly we will “forget” the last available true observation. The smaller <span class="math notranslate nohighlight">\(\alpha\)</span> is, the more influence the previous observations have and the smoother the series is.</p>
<p>Exponentiality is hidden in the recursiveness of the function – we multiply by <span class="math notranslate nohighlight">\((1-\alpha)\)</span> each time, which already contains a multiplication by <span class="math notranslate nohighlight">\((1-\alpha)\)</span> of previous model values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">exponential_smoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        series - dataset with timestamps</span>
<span class="sd">        alpha - float [0.0, 1.0], smoothing parameter</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>  <span class="c1"># first value is same as series</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)):</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">series</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">result</span><span class="p">[</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotExponentialSmoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alphas</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots exponential smoothing with different alphas</span>

<span class="sd">        series - dataset with timestamps</span>
<span class="sd">        alphas - list of floats, smoothing parameters</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                <span class="n">exponential_smoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alpha</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Alpha </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">series</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Actual&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Exponential Smoothing&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotExponentialSmoothing</span><span class="p">(</span><span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/68e6c7347185bdadd25039e50cac6d2847622558670b806795560b2a99a34561.png" src="../../_images/68e6c7347185bdadd25039e50cac6d2847622558670b806795560b2a99a34561.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotExponentialSmoothing</span><span class="p">(</span><span class="n">currency</span><span class="o">.</span><span class="n">GEMS_GEMS_SPENT</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/311d9cf4bd859ce3cbe0278110fc113ca22a38a5a183fcb060de0e7a7bfc3d83.png" src="../../_images/311d9cf4bd859ce3cbe0278110fc113ca22a38a5a183fcb060de0e7a7bfc3d83.png" />
</div>
</div>
</section>
<section id="double-exponential-smoothing">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">Double exponential smoothing</a><a class="headerlink" href="#double-exponential-smoothing" title="Permalink to this heading">#</a></h2>
<p>Up to now, the methods that we’ve discussed have been for a single future point prediction (with some nice smoothing). That is cool, but it is also not enough. Let’s extend exponential smoothing so that we can predict two future points (of course, we will also include more smoothing).</p>
<p>Series decomposition will help us – we obtain two components: intercept (i.e. level) <span class="math notranslate nohighlight">\(\ell\)</span> and slope (i.e. trend) <span class="math notranslate nohighlight">\(b\)</span>. We have learnt to predict intercept (or expected series value) with our previous methods; now, we will apply the same exponential smoothing to the trend by assuming that the future direction of the time series changes depends on the previous weighted changes. As a result, we get the following set of functions:</p>
<div class="math notranslate nohighlight">
\[\ell_x = \alpha y_x + (1-\alpha)(\ell_{x-1} + b_{x-1})\]</div>
<div class="math notranslate nohighlight">
\[b_x = \beta(\ell_x - \ell_{x-1}) + (1-\beta)b_{x-1}\]</div>
<div class="math notranslate nohighlight">
\[\hat{y}_{x+1} = \ell_x + b_x\]</div>
<p>The first one describes the intercept, which, as before, depends on the current value of the series. The second term is now split into previous values of the level and of the trend. The second function describes the trend, which depends on the level changes at the current step and on the previous value of the trend. In this case, the <span class="math notranslate nohighlight">\(\beta\)</span> coefficient is a weight for exponential smoothing. The final prediction is the sum of the model values of the intercept and trend.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">double_exponential_smoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        series - dataset with timeseries</span>
<span class="sd">        alpha - float [0.0, 1.0], smoothing parameter for level</span>
<span class="sd">        beta - float [0.0, 1.0], smoothing parameter for trend</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># first value is same as series</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[</span><span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">level</span><span class="p">,</span> <span class="n">trend</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">series</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">):</span>  <span class="c1"># forecasting</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">series</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
        <span class="n">last_level</span><span class="p">,</span> <span class="n">level</span> <span class="o">=</span> <span class="n">level</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">value</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">level</span> <span class="o">+</span> <span class="n">trend</span><span class="p">)</span>
        <span class="n">trend</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">level</span> <span class="o">-</span> <span class="n">last_level</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">trend</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">level</span> <span class="o">+</span> <span class="n">trend</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">plotDoubleExponentialSmoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">betas</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots double exponential smoothing with different alphas and betas</span>

<span class="sd">        series - dataset with timestamps</span>
<span class="sd">        alphas - list of floats, smoothing parameters for level</span>
<span class="sd">        betas - list of floats, smoothing parameters for trend</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">beta</span> <span class="ow">in</span> <span class="n">betas</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                    <span class="n">double_exponential_smoothing</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">),</span>
                    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Alpha </span><span class="si">{}</span><span class="s2">, beta </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">),</span>
                <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">series</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Actual&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Double Exponential Smoothing&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotDoubleExponentialSmoothing</span><span class="p">(</span><span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">],</span> <span class="n">betas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/21384e4fb8ff7d56bf027a81270d6837211229bda5141dd887a0839ccd30b17e.png" src="../../_images/21384e4fb8ff7d56bf027a81270d6837211229bda5141dd887a0839ccd30b17e.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotDoubleExponentialSmoothing</span><span class="p">(</span>
    <span class="n">currency</span><span class="o">.</span><span class="n">GEMS_GEMS_SPENT</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">],</span> <span class="n">betas</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a9be7870e8278f2924bc36326f1fcc3269875790ab242c01553ffc220f4e8206.png" src="../../_images/a9be7870e8278f2924bc36326f1fcc3269875790ab242c01553ffc220f4e8206.png" />
</div>
</div>
<p>Now we have to tune two parameters: <span class="math notranslate nohighlight">\(\alpha\)</span> and <span class="math notranslate nohighlight">\(\beta\)</span>. The former is responsible for the series smoothing around the trend, the latter for the smoothing of the trend itself. The larger the values, the more weight the most recent observations will have and the less smoothed the model series will be. Certain combinations of the parameters may produce strange results, especially if set manually. We’ll look into choosing parameters automatically in a bit; before that, let’s discuss triple exponential smoothing.</p>
</section>
<section id="triple-exponential-smoothing-a-k-a-holt-winters">
<h2><a class="toc-backref" href="#id8" role="doc-backlink">Triple exponential smoothing a.k.a. Holt-Winters</a><a class="headerlink" href="#triple-exponential-smoothing-a-k-a-holt-winters" title="Permalink to this heading">#</a></h2>
<p>We’ve looked at exponential smoothing and double exponential smoothing. This time, we’re going into <em>triple</em> exponential smoothing.</p>
<p>As you could have guessed, the idea is to add a third component - seasonality. This means that we should not use this method if our time series is not expected to have seasonality. Seasonal components in the model will explain repeated variations around intercept and trend, and it will be specified by the length of the season, in other words by the period after which the variations repeat. For each observation in the season, there is a separate component; for example, if the length of the season is 7 days (a weekly seasonality), we will have 7 seasonal components, one for each day of the week.</p>
<p>With this, let’s write out a new system of equations:</p>
<div class="math notranslate nohighlight">
\[\ell_x = \alpha(y_x - s_{x-L}) + (1-\alpha)(\ell_{x-1} + b_{x-1})\]</div>
<div class="math notranslate nohighlight">
\[b_x = \beta(\ell_x - \ell_{x-1}) + (1-\beta)b_{x-1}\]</div>
<div class="math notranslate nohighlight">
\[s_x = \gamma(y_x - \ell_x) + (1-\gamma)s_{x-L}\]</div>
<div class="math notranslate nohighlight">
\[\hat{y}_{x+m} = \ell_x + mb_x + s_{x-L+1+(m-1)modL}\]</div>
<p>The intercept now depends on the current value of the series minus any corresponding seasonal component. Trend remains unchanged, and the seasonal component depends on the current value of the series minus the intercept and on the previous value of the component. Take into account that the component is smoothed through all the available seasons; for example, if we have a Monday component, then it will only be averaged with other Mondays. You can read more on how averaging works and how the initial approximation of the trend and seasonal components is done <a class="reference external" href="http://www.itl.nist.gov/div898/handbook/pmc/section4/pmc435.htm">here</a>. Now that we have the seasonal component, we can predict not just one or two steps ahead but an arbitrary <span class="math notranslate nohighlight">\(m\)</span> future steps ahead, which is very encouraging.</p>
<p>Below is the code for a triple exponential smoothing model, which is also known by the last names of its creators, Charles Holt and his student Peter Winters. Additionally, the Brutlag method was included in the model to produce confidence intervals:</p>
<div class="math notranslate nohighlight">
\[\hat y_{max_x}=\ell_{x−1}+b_{x−1}+s_{x−T}+m⋅d_{t−T}\]</div>
<div class="math notranslate nohighlight">
\[\hat y_{min_x}=\ell_{x−1}+b_{x−1}+s_{x−T}-m⋅d_{t−T}\]</div>
<div class="math notranslate nohighlight">
\[d_t=\gamma∣y_t−\hat y_t∣+(1−\gamma)d_{t−T},\]</div>
<p>where <span class="math notranslate nohighlight">\(T\)</span> is the length of the season, <span class="math notranslate nohighlight">\(d\)</span> is the predicted deviation. Other parameters were taken from triple exponential smoothing. You can read more about the method and its applicability to anomaly detection in time series <a class="reference external" href="http://fedcsis.org/proceedings/2012/pliks/118.pdf">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">HoltWinters</span><span class="p">:</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Holt-Winters model with the anomalies detection using Brutlag method</span>

<span class="sd">    # series - initial time series</span>
<span class="sd">    # slen - length of a season</span>
<span class="sd">    # alpha, beta, gamma - Holt-Winters model coefficients</span>
<span class="sd">    # n_preds - predictions horizon</span>
<span class="sd">    # scaling_factor - sets the width of the confidence interval by Brutlag (usually takes values from 2 to 3)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">series</span><span class="p">,</span> <span class="n">slen</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">n_preds</span><span class="p">,</span> <span class="n">scaling_factor</span><span class="o">=</span><span class="mf">1.96</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">series</span> <span class="o">=</span> <span class="n">series</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slen</span> <span class="o">=</span> <span class="n">slen</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_preds</span> <span class="o">=</span> <span class="n">n_preds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">=</span> <span class="n">scaling_factor</span>

    <span class="k">def</span> <span class="nf">initial_trend</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">sum</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">):</span>
            <span class="nb">sum</span> <span class="o">+=</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span>
        <span class="k">return</span> <span class="nb">sum</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span>

    <span class="k">def</span> <span class="nf">initial_seasonal_components</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">seasonals</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">season_averages</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">n_seasons</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">)</span>
        <span class="c1"># let&#39;s calculate season averages</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_seasons</span><span class="p">):</span>
            <span class="n">season_averages</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">slen</span> <span class="o">*</span> <span class="n">j</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span> <span class="o">*</span> <span class="n">j</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">])</span>
                <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="c1"># let&#39;s calculate initial values</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">):</span>
            <span class="n">sum_of_vals_over_avg</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_seasons</span><span class="p">):</span>
                <span class="n">sum_of_vals_over_avg</span> <span class="o">+=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">slen</span> <span class="o">*</span> <span class="n">j</span> <span class="o">+</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">season_averages</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                <span class="p">)</span>
            <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_of_vals_over_avg</span> <span class="o">/</span> <span class="n">n_seasons</span>
        <span class="k">return</span> <span class="n">seasonals</span>

    <span class="k">def</span> <span class="nf">triple_exponential_smoothing</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Smooth</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Season</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Trend</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">UpperBond</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">LowerBond</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">seasonals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_seasonal_components</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_preds</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># components initialization</span>
                <span class="n">smooth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">trend</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial_trend</span><span class="p">()</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Smooth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smooth</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Trend</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trend</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">Season</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seasonals</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">])</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">UpperBond</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">LowerBond</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">):</span>  <span class="c1"># predicting</span>
                <span class="n">m</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">smooth</span> <span class="o">+</span> <span class="n">m</span> <span class="o">*</span> <span class="n">trend</span><span class="p">)</span> <span class="o">+</span> <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">])</span>

                <span class="c1"># when predicting we increase uncertainty on each step</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.01</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">last_smooth</span><span class="p">,</span> <span class="n">smooth</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">smooth</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">*</span> <span class="p">(</span><span class="n">val</span> <span class="o">-</span> <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">])</span>
                    <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">smooth</span> <span class="o">+</span> <span class="n">trend</span><span class="p">),</span>
                <span class="p">)</span>
                <span class="n">trend</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">*</span> <span class="p">(</span><span class="n">smooth</span> <span class="o">-</span> <span class="n">last_smooth</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span> <span class="o">*</span> <span class="n">trend</span>
                <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="n">val</span> <span class="o">-</span> <span class="n">smooth</span><span class="p">)</span>
                    <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span> <span class="o">*</span> <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smooth</span> <span class="o">+</span> <span class="n">trend</span> <span class="o">+</span> <span class="n">seasonals</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">])</span>

                <span class="c1"># Deviation is calculated according to Brutlag algorithm.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">series</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                    <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">UpperBond</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">LowerBond</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">result</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">Smooth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">smooth</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Trend</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trend</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Season</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seasonals</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">slen</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="time-series-cross-validation">
<h2><a class="toc-backref" href="#id9" role="doc-backlink">Time series cross validation</a><a class="headerlink" href="#time-series-cross-validation" title="Permalink to this heading">#</a></h2>
<p>Before we start building a model, let’s first discuss how to estimate model parameters automatically.</p>
<p>There is nothing unusual here; as always, we have to choose a loss function suitable for the task that will tell us how closely the model approximates the data. Then, using cross-validation, we will evaluate our chosen loss function for the given model parameters, calculate the gradient, adjust the model parameters, and so on, eventually descending to the global minimum.</p>
<p>You may be asking how to do cross-validation for time series because time series have this temporal structure and one cannot randomly mix values in a fold while preserving this structure. With randomization, all time dependencies between observations will be lost. This is why we will have to use a more tricky approach in optimizing the model parameters. I don’t know if there’s an official name to this, but on <a class="reference external" href="https://stats.stackexchange.com/questions/14099/using-k-fold-cross-validation-for-time-series-model-selection">CrossValidated</a>, where one can find all answers but the Answer to the Ultimate Question of Life, the Universe, and Everything, the proposed name for this method is “cross-validation on a rolling basis”.</p>
<p>The idea is rather simple – we train our model on a small segment of the time series from the beginning until some <span class="math notranslate nohighlight">\(t\)</span>, make predictions for the next <span class="math notranslate nohighlight">\(t+n\)</span> steps, and calculate an error. Then, we expand our training sample to <span class="math notranslate nohighlight">\(t+n\)</span> value, make predictions from <span class="math notranslate nohighlight">\(t+n\)</span> until <span class="math notranslate nohighlight">\(t+2*n\)</span>, and continue moving our test segment of the time series until we hit the last available observation. As a result, we have as many folds as <span class="math notranslate nohighlight">\(n\)</span> will fit between the initial training sample and the last observation.</p>
<img src="../../_static/img/topic9_time_series_cv.png"/>
<p>Now, knowing how to set up cross-validation, we can find the optimal parameters for the Holt-Winters model. Recall that we have daily seasonality in ads, hence the <code class="docutils literal notranslate"><span class="pre">slen=24</span></code> parameter.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> \
    <span class="n">TimeSeriesSplit</span>  <span class="c1"># you have everything done for you</span>


<span class="k">def</span> <span class="nf">timeseriesCVscore</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">series</span><span class="p">,</span> <span class="n">loss_function</span><span class="o">=</span><span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">slen</span><span class="o">=</span><span class="mi">24</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns error on CV  </span>

<span class="sd">        params - vector of parameters for optimization</span>
<span class="sd">        series - dataset with timeseries</span>
<span class="sd">        slen - season length for Holt-Winters model</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># errors array</span>
    <span class="n">errors</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">values</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">values</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="n">params</span>

    <span class="c1"># set the number of folds for cross-validation</span>
    <span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># iterating over folds, train model on each, forecast and calculate error</span>
    <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">values</span><span class="p">):</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">HoltWinters</span><span class="p">(</span>
            <span class="n">series</span><span class="o">=</span><span class="n">values</span><span class="p">[</span><span class="n">train</span><span class="p">],</span>
            <span class="n">slen</span><span class="o">=</span><span class="n">slen</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span>
            <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
            <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span>
            <span class="n">n_preds</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">triple_exponential_smoothing</span><span class="p">()</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">result</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)</span> <span class="p">:]</span>
        <span class="n">actual</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">actual</span><span class="p">)</span>
        <span class="n">errors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">errors</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>In the Holt-Winters model, as well as in the other models of exponential smoothing, there’s a constraint on how large the smoothing parameters can be, each of them ranging from 0 to 1. Therefore, in order to minimize our loss function, we have to choose an algorithm that supports constraints on model parameters. In our case, we will use the truncated Newton conjugate gradient.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">[:</span><span class="o">-</span><span class="mi">20</span><span class="p">]</span>  <span class="c1"># leave some data for testing</span>

<span class="c1"># initializing model parameters alpha, beta and gamma</span>
<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># Minimizing the loss function</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
    <span class="n">timeseriesCVscore</span><span class="p">,</span>
    <span class="n">x0</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mean_squared_log_error</span><span class="p">),</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;TNC&quot;</span><span class="p">,</span>
    <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
<span class="p">)</span>

<span class="c1"># Take optimal values...</span>
<span class="n">alpha_final</span><span class="p">,</span> <span class="n">beta_final</span><span class="p">,</span> <span class="n">gamma_final</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="n">alpha_final</span><span class="p">,</span> <span class="n">beta_final</span><span class="p">,</span> <span class="n">gamma_final</span><span class="p">)</span>

<span class="c1"># ...and train the model with them, forecasting for the next 50 hours</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">HoltWinters</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">slen</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_final</span><span class="p">,</span>
    <span class="n">beta</span><span class="o">=</span><span class="n">beta_final</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="n">gamma_final</span><span class="p">,</span>
    <span class="n">n_preds</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">scaling_factor</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">triple_exponential_smoothing</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.11912291397687808 0.00269957583214403 0.05376597682877887
CPU times: user 140 ms, sys: 4.97 ms, total: 145 ms
Wall time: 140 ms
</pre></div>
</div>
</div>
</div>
<p>Let’s add some code to render plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotHoltWinters</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        series - dataset with timeseries</span>
<span class="sd">        plot_intervals - show confidence intervals</span>
<span class="sd">        plot_anomalies - show anomalies</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">result</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Model&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">series</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Actual&quot;</span><span class="p">)</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">series</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">result</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Percentage Error: </span><span class="si">{0:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">plot_anomalies</span><span class="p">:</span>
        <span class="n">anomalies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">))</span>
        <span class="n">anomalies</span><span class="p">[</span><span class="n">series</span><span class="o">.</span><span class="n">values</span> <span class="o">&lt;</span> <span class="n">model</span><span class="o">.</span><span class="n">LowerBond</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)]]</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">values</span><span class="p">[</span>
            <span class="n">series</span><span class="o">.</span><span class="n">values</span> <span class="o">&lt;</span> <span class="n">model</span><span class="o">.</span><span class="n">LowerBond</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)]</span>
        <span class="p">]</span>
        <span class="n">anomalies</span><span class="p">[</span><span class="n">series</span><span class="o">.</span><span class="n">values</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">UpperBond</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)]]</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">values</span><span class="p">[</span>
            <span class="n">series</span><span class="o">.</span><span class="n">values</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">UpperBond</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)]</span>
        <span class="p">]</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">anomalies</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Anomalies&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">plot_intervals</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">UpperBond</span><span class="p">,</span> <span class="s2">&quot;r--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Up/Low confidence&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">LowerBond</span><span class="p">,</span> <span class="s2">&quot;r--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">result</span><span class="p">)),</span>
            <span class="n">y1</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">UpperBond</span><span class="p">,</span>
            <span class="n">y2</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">LowerBond</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
            <span class="n">color</span><span class="o">=</span><span class="s2">&quot;grey&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">),</span>
        <span class="n">ymin</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">LowerBond</span><span class="p">),</span>
        <span class="n">ymax</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">UpperBond</span><span class="p">),</span>
        <span class="n">linestyles</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvspan</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">series</span><span class="p">)</span> <span class="o">-</span> <span class="mi">20</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">result</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgrey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotHoltWinters</span><span class="p">(</span><span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e7736028646478309717455c03c6abb95c8f18005cbb4cb3ac9885ec12dd36e7.png" src="../../_images/e7736028646478309717455c03c6abb95c8f18005cbb4cb3ac9885ec12dd36e7.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotHoltWinters</span><span class="p">(</span><span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0540e865a2c2d8b9c6e6ddb2411052132f24cb6e2d3995c3d4461c9a65b71b50.png" src="../../_images/0540e865a2c2d8b9c6e6ddb2411052132f24cb6e2d3995c3d4461c9a65b71b50.png" />
</div>
</div>
<p>Judging by the plots, our model was able to successfully approximate the initial time series, capturing the daily seasonality, overall downwards trend, and even some anomalies. If you look at the model deviations, you can clearly see that the model reacts quite sharply to changes in the structure of the series but then quickly returns the deviation to the normal values, essentially “forgetting” the past. This feature of the model allows us to quickly build anomaly detection systems, even for noisy series data, without spending too much time and money on preparing the data and training the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Brutlag&#39;s predicted deviation&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/18ac814572b5e5e7d6ceec891045f693a976100947be91fcc98dd78adc7bd949.png" src="../../_images/18ac814572b5e5e7d6ceec891045f693a976100947be91fcc98dd78adc7bd949.png" />
</div>
</div>
<p>We’ll apply the same algorithm for the second series which, as you may recall, has trend and a 30-day seasonality.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">currency</span><span class="o">.</span><span class="n">GEMS_GEMS_SPENT</span><span class="p">[:</span><span class="o">-</span><span class="mi">50</span><span class="p">]</span>
<span class="n">slen</span> <span class="o">=</span> <span class="mi">30</span>  <span class="c1"># 30-day seasonality</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span>
    <span class="n">timeseriesCVscore</span><span class="p">,</span>
    <span class="n">x0</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">mean_absolute_percentage_error</span><span class="p">,</span> <span class="n">slen</span><span class="p">),</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;TNC&quot;</span><span class="p">,</span>
    <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
<span class="p">)</span>

<span class="n">alpha_final</span><span class="p">,</span> <span class="n">beta_final</span><span class="p">,</span> <span class="n">gamma_final</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">x</span>
<span class="nb">print</span><span class="p">(</span><span class="n">alpha_final</span><span class="p">,</span> <span class="n">beta_final</span><span class="p">,</span> <span class="n">gamma_final</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">HoltWinters</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">slen</span><span class="o">=</span><span class="n">slen</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_final</span><span class="p">,</span>
    <span class="n">beta</span><span class="o">=</span><span class="n">beta_final</span><span class="p">,</span>
    <span class="n">gamma</span><span class="o">=</span><span class="n">gamma_final</span><span class="p">,</span>
    <span class="n">n_preds</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">scaling_factor</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">triple_exponential_smoothing</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.013190344846993662 0.047616267647338284 0.0
CPU times: user 221 ms, sys: 1.76 ms, total: 223 ms
Wall time: 222 ms
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotHoltWinters</span><span class="p">(</span><span class="n">currency</span><span class="o">.</span><span class="n">GEMS_GEMS_SPENT</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/8e481f1a5329b9ea3c16ab274cd1d061e1d9e9af274191b4605546f08b1f524f.png" src="../../_images/8e481f1a5329b9ea3c16ab274cd1d061e1d9e9af274191b4605546f08b1f524f.png" />
</div>
</div>
<p>Looks good! The model caught both upwards trend and seasonal spikes and fits the data quite nicely.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotHoltWinters</span><span class="p">(</span><span class="n">currency</span><span class="o">.</span><span class="n">GEMS_GEMS_SPENT</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/9a80e8268113f929574675de444858e134eca0cdd9c38be05c965df297631f26.png" src="../../_images/9a80e8268113f929574675de444858e134eca0cdd9c38be05c965df297631f26.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">PredictedDeviation</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Brutlag&#39;s predicted deviation&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/dcb25a2188973b67111b28b7aeb93e8fe8fa85e9df7610e653a4139ffb178b96.png" src="../../_images/dcb25a2188973b67111b28b7aeb93e8fe8fa85e9df7610e653a4139ffb178b96.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="econometric-approach">
<h1><a class="toc-backref" href="#id10" role="doc-backlink">Econometric approach</a><a class="headerlink" href="#econometric-approach" title="Permalink to this heading">#</a></h1>
<section id="stationarity">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Stationarity</a><a class="headerlink" href="#stationarity" title="Permalink to this heading">#</a></h2>
<p>Before we start modeling, we should mention such an important property of time series: <a class="reference external" href="https://en.wikipedia.org/wiki/Stationary_process"><strong>stationarity</strong></a>.</p>
<p>If a process is stationary, that means it does not change its statistical properties over time, namely its mean and variance. (The constancy of variance is called <a class="reference external" href="https://en.wikipedia.org/wiki/Homoscedasticity">homoscedasticity</a>)The covariance function does not depend on time; it should only depend on the distance between observations. You can see this visually on the images in the post by <a class="reference external" href="http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/">Sean Abu</a>:</p>
<ul class="simple">
<li><p>The red graph below is not stationary because the mean increases over time.</p></li>
</ul>
<img src="https://habrastorage.org/files/20c/9d8/a63/20c9d8a633ec436f91dccd4aedcc6940.png"/>
<ul class="simple">
<li><p>We were unlucky with the variance and see the varying spread of values over time</p></li>
</ul>
<img src="https://habrastorage.org/files/b88/eec/a67/b88eeca676d642449cab135273fd5a95.png"/>
<ul class="simple">
<li><p>Finally, the covariance of the i th term and the (i + m) th term should not be a function of time. In the following graph, you will notice that the spread becomes closer as time increases. Hence, the covariance is not constant with time in the right chart.</p></li>
</ul>
<img src="https://habrastorage.org/files/2f6/1ee/cb2/2f61eecb20714352840748b826e38680.png"/>
<p>So why is stationarity so important? Because it is easy to make predictions on a stationary series since we can assume that the future statistical properties will not be different from those currently observed. Most of the time-series models, in one way or the other, try to predict those properties (mean or variance, for example). Future predictions would be wrong if the original series were not stationary. Unfortunately, most of the time series that we see outside of textbooks are non-stationary, but we can (and should) change this.</p>
<p>So, in order to combat non-stationarity, we have to know our enemy, so to speak. Let’s see how we can detect it. We will look at white noise and random walks to learn how to get from one to another for free.</p>
<p>White noise chart:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">white_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">white_noise</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/7473a6dccec6d44c488265054936284291a11b39a05dcb7e4f51c3892f1c79cc.png" src="../../_images/7473a6dccec6d44c488265054936284291a11b39a05dcb7e4f51c3892f1c79cc.png" />
</div>
</div>
<p>The process generated by the standard normal distribution is stationary and oscillates around 0 with with deviation of 1. Now, based on this process, we will generate a new one where each subsequent value will depend on the previous one: <span class="math notranslate nohighlight">\(x_t = \rho x_{t-1} + e_t\)</span></p>
<p>Here is the code to render the plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotProcess</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">rho</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>
        <span class="n">x</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="o">=</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">t</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">w</span><span class="p">[</span><span class="n">t</span><span class="p">]</span>

    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s2">&quot;bmh&quot;</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span>
            <span class="s2">&quot;Rho </span><span class="si">{}</span><span class="se">\n</span><span class="s2"> Dickey-Fuller p-value: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">rho</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">stattools</span><span class="o">.</span><span class="n">adfuller</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="p">)</span>


<span class="k">for</span> <span class="n">rho</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mi">1</span><span class="p">]:</span>
    <span class="n">plotProcess</span><span class="p">(</span><span class="n">rho</span><span class="o">=</span><span class="n">rho</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/4832bea8319b7d20b2f024cc2bae35b8c14cc1d8194fe3fc01c3f85472647476.png" src="../../_images/4832bea8319b7d20b2f024cc2bae35b8c14cc1d8194fe3fc01c3f85472647476.png" />
<img alt="../../_images/05a27adfd6aa92ef68329c83ace64b402a2ef8a5991efba54c8e0fe695592a29.png" src="../../_images/05a27adfd6aa92ef68329c83ace64b402a2ef8a5991efba54c8e0fe695592a29.png" />
<img alt="../../_images/9862416f798af327852cdfce6e42d75395baca91ae50302e169f97f526953674.png" src="../../_images/9862416f798af327852cdfce6e42d75395baca91ae50302e169f97f526953674.png" />
<img alt="../../_images/c1f887de0afc365402c8fd8ce0b7b2157937a9a62b79fa184b8007a04bbd20b6.png" src="../../_images/c1f887de0afc365402c8fd8ce0b7b2157937a9a62b79fa184b8007a04bbd20b6.png" />
</div>
</div>
<p>On the first plot, you can see the same stationary white noise as before. On the second plot with <span class="math notranslate nohighlight">\(\rho\)</span> increased to 0.6, wider cycles appeared, but it still appears stationary overall. The third plot deviates even more from the 0 mean but still oscillates about the mean. Finally, with <span class="math notranslate nohighlight">\(\rho=1\)</span>, we have a random walk process i.e. a non-stationary time series.</p>
<p>This happens because, after reaching the critical value, the series <span class="math notranslate nohighlight">\(x_t = \rho x_{t-1} + e_t\)</span> does not return to its mean value. If we subtract <span class="math notranslate nohighlight">\(x_{t-1}\)</span> from both sides, we will get <span class="math notranslate nohighlight">\(x_t - x_{t-1} = (\rho - 1) x_{t-1} + e_t\)</span>, where the expression on the left is referred to as the first difference. If <span class="math notranslate nohighlight">\(\rho=1\)</span>, then the first difference gives us stationary white noise <span class="math notranslate nohighlight">\(e_t\)</span>. This is the main idea behind the <a class="reference external" href="https://en.wikipedia.org/wiki/Dickey%E2%80%93Fuller_test">Dickey-Fuller test</a> for stationarity of time series (testing the presence of a unit root). If we can get a stationary series from a non-stationary series using the first difference, we call those series integrated of order 1. The null hypothesis of the test is that the time series is non-stationary, which was rejected on the first three plots and finally accepted on the last one. We have to say that the first difference is not always enough to get a stationary series as the process might be integrated of order d, d &gt; 1 (and have multiple unit roots). In such cases, the augmented Dickey-Fuller test is used, which checks multiple lags at once.</p>
<p>We can fight non-stationarity using different approaches: various order differences, trend and seasonality removal, smoothing, and transformations like Box-Cox or logarithmic.</p>
</section>
<section id="getting-rid-of-non-stationarity-and-building-sarima">
<h2><a class="toc-backref" href="#id12" role="doc-backlink">Getting rid of non-stationarity and building SARIMA</a><a class="headerlink" href="#getting-rid-of-non-stationarity-and-building-sarima" title="Permalink to this heading">#</a></h2>
<p>Let’s build an ARIMA model by walking through all the <em>circles of hell</em> stages of making a series stationary.</p>
<p>Here is the code to render plots.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">tsplot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">style</span><span class="o">=</span><span class="s2">&quot;bmh&quot;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot time series, its ACF and PACF, calculate Dickey–Fuller test</span>

<span class="sd">        y - timeseries</span>
<span class="sd">        lags - how many lags to include in ACF, PACF calculation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="n">layout</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">ts_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">(</span><span class="n">layout</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">colspan</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">acf_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">(</span><span class="n">layout</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
        <span class="n">pacf_ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot2grid</span><span class="p">(</span><span class="n">layout</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">ts_ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">p_value</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">stattools</span><span class="o">.</span><span class="n">adfuller</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">ts_ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span>
            <span class="s2">&quot;Time Series Analysis Plots</span><span class="se">\n</span><span class="s2"> Dickey-Fuller: p=</span><span class="si">{0:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">smt</span><span class="o">.</span><span class="n">graphics</span><span class="o">.</span><span class="n">plot_acf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="n">lags</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">acf_ax</span><span class="p">)</span>
        <span class="n">smt</span><span class="o">.</span><span class="n">graphics</span><span class="o">.</span><span class="n">plot_pacf</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="n">lags</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">pacf_ax</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsplot</span><span class="p">(</span><span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span> <span class="n">lags</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a1a4b3aeb3f06a0a4b076ea82b63c156367653af5a3905096d96560887b4b364.png" src="../../_images/a1a4b3aeb3f06a0a4b076ea82b63c156367653af5a3905096d96560887b4b364.png" />
</div>
</div>
<p><em>this outlier on partial autocorrelation plot looks like a statsmodels bug, partial autocorrelation shall be &lt;= 1 like any correlation.</em></p>
<p>Surprisingly, the initial series are stationary; the Dickey-Fuller test rejected the null hypothesis that a unit root is present. Actually, we can see this on the plot itself – we do not have a visible trend, so the mean is constant and the variance is pretty much stable. The only thing left is seasonality, which we have to deal with prior to modeling. To do so, let’s take the “seasonal difference”, which means a simple subtraction of the series from itself with a lag that equals the seasonal period.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ads_diff</span> <span class="o">=</span> <span class="n">ads</span><span class="o">.</span><span class="n">Ads</span> <span class="o">-</span> <span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">24</span><span class="p">)</span>
<span class="n">tsplot</span><span class="p">(</span><span class="n">ads_diff</span><span class="p">[</span><span class="mi">24</span><span class="p">:],</span> <span class="n">lags</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f683b3500f3b4de63128fe29b33ef1ea31405dbcee440fe340a0bf235c494f8e.png" src="../../_images/f683b3500f3b4de63128fe29b33ef1ea31405dbcee440fe340a0bf235c494f8e.png" />
</div>
</div>
<p>It is now much better with the visible seasonality gone. However, the autocorrelation function still has too many significant lags. To remove them, we’ll take first differences, subtracting the series from itself with lag 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ads_diff</span> <span class="o">=</span> <span class="n">ads_diff</span> <span class="o">-</span> <span class="n">ads_diff</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">tsplot</span><span class="p">(</span><span class="n">ads_diff</span><span class="p">[</span><span class="mi">24</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:],</span> <span class="n">lags</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0df05af6779392d79037196f43753f367f00262659888b1fab811d958d64ae28.png" src="../../_images/0df05af6779392d79037196f43753f367f00262659888b1fab811d958d64ae28.png" />
</div>
</div>
<p>Perfect! Our series now looks like something indescribable, oscillating around zero. The Dickey-Fuller test indicates that it is stationary, and the number of significant peaks in ACF has dropped. We can finally start modeling!</p>
</section>
<section id="arima-family-crash-course">
<h2><a class="toc-backref" href="#id13" role="doc-backlink">ARIMA-family Crash-Course</a><a class="headerlink" href="#arima-family-crash-course" title="Permalink to this heading">#</a></h2>
<p>We will explain this model by building up letter by letter. <span class="math notranslate nohighlight">\(SARIMA(p, d, q)(P, D, Q, s)\)</span>, Seasonal Autoregression Moving Average model:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(AR(p)\)</span> - autoregression model i.e. regression of the time series onto itself. The basic assumption is that the current series values depend on its previous values with some lag (or several lags). The maximum lag in the model is referred to as <span class="math notranslate nohighlight">\(p\)</span>. To determine the initial <span class="math notranslate nohighlight">\(p\)</span>, you need to look at the PACF plot and find the biggest significant lag after which <strong>most</strong> other lags become insignificant.</p></li>
<li><p><span class="math notranslate nohighlight">\(MA(q)\)</span> - moving average model. Without going into too much detail, this models the error of the time series, again with the assumption that the current error depends on the previous with some lag, which is referred to as <span class="math notranslate nohighlight">\(q\)</span>. The initial value can be found on the ACF plot with the same logic as before.</p></li>
</ul>
<p>Let’s combine our first 4 letters:</p>
<p><span class="math notranslate nohighlight">\(AR(p) + MA(q) = ARMA(p, q)\)</span></p>
<p>What we have here is the Autoregressive–moving-average model! If the series is stationary, it can be approximated with these 4 letters. Let’s continue.</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(I(d)\)</span> - order of integration. This is simply the number of nonseasonal differences needed to make the series stationary. In our case, it’s just 1 because we used first differences.</p></li>
</ul>
<p>Adding this letter to the four gives us the <span class="math notranslate nohighlight">\(ARIMA\)</span> model which can handle non-stationary data with the help of nonseasonal differences. Great, one more letter to go!</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S(s)\)</span> - this is responsible for seasonality and equals the season period length of the series</p></li>
</ul>
<p>With this, we have three parameters: <span class="math notranslate nohighlight">\((P, D, Q)\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P\)</span> - order of autoregression for the seasonal component of the model, which can be derived from PACF. But you need to look at the number of significant lags, which are the multiples of the season period length. For example, if the period equals 24 and we see the 24-th and 48-th lags are significant in the PACF, that means the initial <span class="math notranslate nohighlight">\(P\)</span> should be 2.</p></li>
<li><p><span class="math notranslate nohighlight">\(Q\)</span> - similar logic using the ACF plot instead.</p></li>
<li><p><span class="math notranslate nohighlight">\(D\)</span> - order of seasonal integration. This can be equal to 1 or 0, depending on whether seasonal differences were applied or not.</p></li>
</ul>
<p>Now that we know how to set the initial parameters, let’s have a look at the final plot once again and set the parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsplot</span><span class="p">(</span><span class="n">ads_diff</span><span class="p">[</span><span class="mi">24</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:],</span> <span class="n">lags</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0df05af6779392d79037196f43753f367f00262659888b1fab811d958d64ae28.png" src="../../_images/0df05af6779392d79037196f43753f367f00262659888b1fab811d958d64ae28.png" />
</div>
</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(p\)</span> is most probably 4 since it is the last significant lag on the PACF, after which, most others are not significant.</p></li>
<li><p><span class="math notranslate nohighlight">\(d\)</span> equals 1 because we had first differences</p></li>
<li><p><span class="math notranslate nohighlight">\(q\)</span> should be somewhere around 4 as well as seen on the ACF</p></li>
<li><p><span class="math notranslate nohighlight">\(P\)</span> might be 2, since 24-th and 48-th lags are somewhat significant on the PACF</p></li>
<li><p><span class="math notranslate nohighlight">\(D\)</span> again equals 1 because we performed seasonal differentiation</p></li>
<li><p><span class="math notranslate nohighlight">\(Q\)</span> is probably 1. The 24-th lag on ACF is significant while the 48-th is not.</p></li>
</ul>
<p>Let’s test various models and see which one is better.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># setting initial values and some bounds for them</span>
<span class="n">ps</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">qs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">Ps</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">Qs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <span class="mi">24</span>  <span class="c1"># season length is still 24</span>

<span class="c1"># creating list with all the possible combinations of parameters</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="n">product</span><span class="p">(</span><span class="n">ps</span><span class="p">,</span> <span class="n">qs</span><span class="p">,</span> <span class="n">Ps</span><span class="p">,</span> <span class="n">Qs</span><span class="p">)</span>
<span class="n">parameters_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
<span class="nb">len</span><span class="p">(</span><span class="n">parameters_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>36
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">optimizeSARIMA</span><span class="p">(</span><span class="n">parameters_list</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">s</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return dataframe with parameters and corresponding AIC</span>

<span class="sd">        parameters_list - list with (p, q, P, Q) tuples</span>
<span class="sd">        d - integration order in ARIMA model</span>
<span class="sd">        D - seasonal integration order</span>
<span class="sd">        s - length of season</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_aic</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">parameters_list</span><span class="p">):</span>
        <span class="c1"># we need try-except because on some combinations model fails to converge</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">statespace</span><span class="o">.</span><span class="n">SARIMAX</span><span class="p">(</span>
                <span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span>
                <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">d</span><span class="p">,</span> <span class="n">param</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                <span class="n">seasonal_order</span><span class="o">=</span><span class="p">(</span><span class="n">param</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">D</span><span class="p">,</span> <span class="n">param</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">s</span><span class="p">),</span>
            <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">disp</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">aic</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">aic</span>
        <span class="c1"># saving best model, AIC and parameters</span>
        <span class="k">if</span> <span class="n">aic</span> <span class="o">&lt;</span> <span class="n">best_aic</span><span class="p">:</span>
            <span class="n">best_model</span> <span class="o">=</span> <span class="n">model</span>
            <span class="n">best_aic</span> <span class="o">=</span> <span class="n">aic</span>
            <span class="n">best_param</span> <span class="o">=</span> <span class="n">param</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">param</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">aic</span><span class="p">])</span>

    <span class="n">result_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
    <span class="n">result_table</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;parameters&quot;</span><span class="p">,</span> <span class="s2">&quot;aic&quot;</span><span class="p">]</span>
    <span class="c1"># sorting in ascending order, the lower AIC is - the better</span>
    <span class="n">result_table</span> <span class="o">=</span> <span class="n">result_table</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;aic&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span>
        <span class="n">drop</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">result_table</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">result_table</span> <span class="o">=</span> <span class="n">optimizeSARIMA</span><span class="p">(</span><span class="n">parameters_list</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "e078e5f4732341b08e5e86f47cb5b005"}</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 35.3 s, sys: 1.8 s, total: 37.1 s
Wall time: 37.3 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">result_table</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>parameters</th>
      <th>aic</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(2, 3, 1, 1)</td>
      <td>3888.642174</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(3, 2, 1, 1)</td>
      <td>3888.763568</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(4, 2, 1, 1)</td>
      <td>3890.279740</td>
    </tr>
    <tr>
      <th>3</th>
      <td>(3, 3, 1, 1)</td>
      <td>3890.513196</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(2, 4, 1, 1)</td>
      <td>3892.302849</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set the parameters that give the lowest AIC</span>
<span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span> <span class="o">=</span> <span class="n">result_table</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">best_model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">tsa</span><span class="o">.</span><span class="n">statespace</span><span class="o">.</span><span class="n">SARIMAX</span><span class="p">(</span>
    <span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">q</span><span class="p">),</span> <span class="n">seasonal_order</span><span class="o">=</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">disp</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>                                      SARIMAX Results                                       
============================================================================================
Dep. Variable:                                  Ads   No. Observations:                  216
Model:             SARIMAX(2, 1, 3)x(1, 1, [1], 24)   Log Likelihood               -1936.321
Date:                              Mon, 19 Aug 2024   AIC                           3888.642
Time:                                      18:34:51   BIC                           3914.660
Sample:                                  09-13-2017   HQIC                          3899.181
                                       - 09-21-2017                                         
Covariance Type:                                opg                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
ar.L1          0.7913      0.270      2.928      0.003       0.262       1.321
ar.L2         -0.5503      0.306     -1.799      0.072      -1.150       0.049
ma.L1         -0.7316      0.262     -2.793      0.005      -1.245      -0.218
ma.L2          0.5651      0.282      2.005      0.045       0.013       1.118
ma.L3         -0.1811      0.092     -1.964      0.049      -0.362      -0.000
ar.S.L24       0.3312      0.076      4.351      0.000       0.182       0.480
ma.S.L24      -0.7635      0.104     -7.361      0.000      -0.967      -0.560
sigma2      4.574e+07   5.61e-09   8.15e+15      0.000    4.57e+07    4.57e+07
===================================================================================
Ljung-Box (L1) (Q):                   0.88   Jarque-Bera (JB):                10.56
Prob(Q):                              0.35   Prob(JB):                         0.01
Heteroskedasticity (H):               0.65   Skew:                            -0.28
Prob(H) (two-sided):                  0.09   Kurtosis:                         4.00
===================================================================================

Warnings:
[1] Covariance matrix calculated using the outer product of gradients (complex-step).
[2] Covariance matrix is singular or near-singular, with condition number 2.18e+32. Standard errors may be unstable.
</pre></div>
</div>
</div>
</div>
<p>Let’s inspect the residuals of the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsplot</span><span class="p">(</span><span class="n">best_model</span><span class="o">.</span><span class="n">resid</span><span class="p">[</span><span class="mi">24</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:],</span> <span class="n">lags</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/1aa17e91ce8c284744fa9063d79e97d2795835fb27664bec19fc519b7561cd56.png" src="../../_images/1aa17e91ce8c284744fa9063d79e97d2795835fb27664bec19fc519b7561cd56.png" />
</div>
</div>
<p>It is clear that the residuals are stationary, and there are no apparent autocorrelations. Let’s make predictions using our model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotSARIMA</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots model vs predicted values</span>

<span class="sd">        series - dataset with timeseries</span>
<span class="sd">        model - fitted SARIMA model</span>
<span class="sd">        n_steps - number of steps to predict in the future</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># adding model values</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">series</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;actual&quot;</span><span class="p">]</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;arima_model&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fittedvalues</span>
    <span class="c1"># making a shift on s+d steps, because these values were unobserved by the model</span>
    <span class="c1"># due to the differentiating</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;arima_model&quot;</span><span class="p">][:</span> <span class="n">s</span> <span class="o">+</span> <span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="c1"># forecasting on n_steps forward</span>
    <span class="n">forecast</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">n_steps</span><span class="p">)</span>
    <span class="n">forecast</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">arima_model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">forecast</span><span class="p">)</span>
    <span class="c1"># calculate error, again having shifted on s+d steps from the beginning</span>
    <span class="n">error</span> <span class="o">=</span> <span class="n">mean_absolute_percentage_error</span><span class="p">(</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;actual&quot;</span><span class="p">][</span><span class="n">s</span> <span class="o">+</span> <span class="n">d</span> <span class="p">:],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;arima_model&quot;</span><span class="p">][</span><span class="n">s</span> <span class="o">+</span> <span class="n">d</span> <span class="p">:]</span>
    <span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Mean Absolute Percentage Error: </span><span class="si">{0:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">forecast</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvspan</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">forecast</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;lightgrey&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">actual</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;actual&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotSARIMA</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="nn">/var/folders/n0/1qj4_6k97ms4rnr_bsfq6j40018_cq/T/ipykernel_41749/2337694703.py</span> in <span class="ni">?</span><span class="nt">()</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">plotSARIMA</span><span class="p">(</span><span class="n">ads</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>

<span class="nn">/var/folders/n0/1qj4_6k97ms4rnr_bsfq6j40018_cq/T/ipykernel_41749/3069305344.py</span> in <span class="ni">?</span><span class="nt">(series, model, n_steps)</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span>     <span class="n">data</span><span class="p">[</span><span class="s2">&quot;arima_model&quot;</span><span class="p">][:</span> <span class="n">s</span> <span class="o">+</span> <span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> 
<span class="g g-Whitespace">     </span><span class="mi">18</span>     <span class="c1"># forecasting on n_steps forward</span>
<span class="g g-Whitespace">     </span><span class="mi">19</span>     <span class="n">forecast</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">n_steps</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">20</span>     <span class="n">forecast</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">arima_model</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">forecast</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>     <span class="c1"># calculate error, again having shifted on s+d steps from the beginning</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>     <span class="n">error</span> <span class="o">=</span> <span class="n">mean_absolute_percentage_error</span><span class="p">(</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span>         <span class="n">data</span><span class="p">[</span><span class="s2">&quot;actual&quot;</span><span class="p">][</span><span class="n">s</span> <span class="o">+</span> <span class="n">d</span> <span class="p">:],</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;arima_model&quot;</span><span class="p">][</span><span class="n">s</span> <span class="o">+</span> <span class="n">d</span> <span class="p">:]</span>

<span class="nn">~/Library/Caches/pypoetry/virtualenvs/mlcourse-ai-czBTtoES-py3.12/lib/python3.12/site-packages/pandas/core/generic.py</span> in <span class="ni">?</span><span class="nt">(self, name)</span>
<span class="g g-Whitespace">   </span><span class="mi">6295</span>             <span class="ow">and</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_accessors</span>
<span class="g g-Whitespace">   </span><span class="mi">6296</span>             <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_info_axis</span><span class="o">.</span><span class="n">_can_hold_identifiers_and_holds_name</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">6297</span>         <span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">6298</span>             <span class="k">return</span> <span class="bp">self</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
<span class="ne">-&gt; </span><span class="mi">6299</span>         <span class="k">return</span> <span class="nb">object</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>

<span class="ne">AttributeError</span>: &#39;Series&#39; object has no attribute &#39;append&#39;
</pre></div>
</div>
</div>
</div>
<p>In the end, we got very adequate predictions. Our model was wrong by 4.01% on average, which is very, very good. However, the overall costs of preparing data, making the series stationary, and selecting parameters might not be worth this accuracy.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="linear-and-not-only-models-for-time-series">
<h1><a class="toc-backref" href="#id14" role="doc-backlink">Linear (and not only) models for time series</a><a class="headerlink" href="#linear-and-not-only-models-for-time-series" title="Permalink to this heading">#</a></h1>
<p>Often, in my job, I have to build models with <a class="reference external" href="http://fastgood.cheap"><em>fast, good, cheap</em></a> as my only guiding principle. That means that some of these models will never be considered “production ready” as they demand too much time for data preparation (as in SARIMA) or require frequent re-training on new data (again, SARIMA) or are difficult to tune (good example - SARIMA). Therefore, it’s very often much easier to select a few features from the existing time series and build a simple linear regression model or, say, a random forest. It is good and cheap.</p>
<p>This approach is not backed by theory and breaks several assumptions (e.g. Gauss-Markov theorem, especially for errors being uncorrelated), but it is very useful in practice and is often used in machine learning competitions.</p>
<section id="feature-extraction">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">Feature extraction</a><a class="headerlink" href="#feature-extraction" title="Permalink to this heading">#</a></h2>
<p>The model needs features, and all we have is a 1-dimensional time series. What features can we extract?</p>
<ul class="simple">
<li><p>Time series lags</p></li>
<li><p>Window statistics:</p>
<ul>
<li><p>Max/min value of series in a window</p></li>
<li><p>Average/median value in a window</p></li>
<li><p>Window variance</p></li>
<li><p>etc.</p></li>
</ul>
</li>
<li><p>Date and time features:</p>
<ul>
<li><p>Minute of an hour, hour of a day, day of the week, and so on</p></li>
<li><p>Is this day a holiday? Maybe there is a special event? Represent that as a boolean feature</p></li>
</ul>
</li>
<li><p>Target encoding</p></li>
<li><p>Forecasts from other models (note that we can lose the speed of prediction this way)</p></li>
</ul>
<p>Let’s run through some of the methods and see what we can extract from our ads time series data.</p>
</section>
<section id="time-series-lags">
<h2><a class="toc-backref" href="#id16" role="doc-backlink">Time series lags</a><a class="headerlink" href="#time-series-lags" title="Permalink to this heading">#</a></h2>
<p>Shifting the series <span class="math notranslate nohighlight">\(n\)</span> steps back, we get a feature column where the current value of time series is aligned with its value at time <span class="math notranslate nohighlight">\(t-n\)</span>. If we make a 1 lag shift and train a model on that feature, the model will be able to forecast 1 step ahead from having observed the current state of the series. Increasing the lag, say, up to 6, will allow the model to make predictions 6 steps ahead; however it will use data observed 6 steps back. If something fundamentally changes the series during that unobserved period, the model will not catch these changes and will return forecasts with a large error. Therefore, during the initial lag selection, one has to find a balance between the optimal prediction quality and the length of the forecasting horizon.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Creating a copy of the initial datagrame to make various transformations</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
<span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Adding the lag of the target variable from 6 steps back up to 24</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">25</span><span class="p">):</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;lag_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># take a look at the new dataframe</span>
<span class="n">data</span><span class="o">.</span><span class="n">tail</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Great, we have generated a dataset here. Why don’t we now train a model?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># for time-series cross-validation set 5 folds</span>
<span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">timeseries_train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform train-test split with respect to time series structure</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># get the index after which test set starts</span>
    <span class="n">test_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">))</span>

    <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">:]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># reserve 30% of data for testing</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">timeseries_train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># machine learning in two lines</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plotModelResults</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots modelled vs fact values, prediction intervals and anomalies</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="s2">&quot;g&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;prediction&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;actual&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">plot_intervals</span><span class="p">:</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">tscv</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_absolute_error&quot;</span>
        <span class="p">)</span>
        <span class="n">mae</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">deviation</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

        <span class="n">scale</span> <span class="o">=</span> <span class="mf">1.96</span>
        <span class="n">lower</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">-</span> <span class="p">(</span><span class="n">mae</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">deviation</span><span class="p">)</span>
        <span class="n">upper</span> <span class="o">=</span> <span class="n">prediction</span> <span class="o">+</span> <span class="p">(</span><span class="n">mae</span> <span class="o">+</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">deviation</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="s2">&quot;r--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;upper bond / lower bond&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">upper</span><span class="p">,</span> <span class="s2">&quot;r--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">plot_anomalies</span><span class="p">:</span>
            <span class="n">anomalies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
            <span class="n">anomalies</span><span class="p">[</span><span class="n">y_test</span> <span class="o">&lt;</span> <span class="n">lower</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">&lt;</span> <span class="n">lower</span><span class="p">]</span>
            <span class="n">anomalies</span><span class="p">[</span><span class="n">y_test</span> <span class="o">&gt;</span> <span class="n">upper</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">y_test</span> <span class="o">&gt;</span> <span class="n">upper</span><span class="p">]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">anomalies</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Anomalies&quot;</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">mean_absolute_percentage_error</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Mean absolute percentage error </span><span class="si">{0:.2f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">error</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plotCoefficients</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots sorted coefficient values of the model</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">coefs</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;coef&quot;</span><span class="p">]</span>
    <span class="n">coefs</span><span class="p">[</span><span class="s2">&quot;abs&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">)</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">coefs</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">&quot;abs&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;abs&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
    <span class="n">coefs</span><span class="o">.</span><span class="n">coef</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">coefs</span><span class="p">),</span> <span class="n">linestyles</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotModelResults</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plotCoefficients</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Simple lags and linear regression gave us predictions that are not that far off from SARIMA in terms of quality. There are many unnecessary features, so we’ll do feature selection in a little while. For now, let’s continue engineering!</p>
<p>We’ll add hour, day of week, and a boolean for <code class="docutils literal notranslate"><span class="pre">is_weekend</span></code>. To do so, we need to transform the current dataframe index into the <code class="docutils literal notranslate"><span class="pre">datetime</span></code> format and extract <code class="docutils literal notranslate"><span class="pre">hour</span></code> and <code class="docutils literal notranslate"><span class="pre">weekday</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">hour</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;weekday&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">weekday</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;is_weekend&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">weekday</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span> <span class="o">*</span> <span class="mi">1</span>
<span class="n">data</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can visualize the resulting features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Encoded features&quot;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">hour</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">weekday</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">is_weekend</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Since we now have different scales in our variables, thousands for the lag features and tens for categorical, we need to transform them into same scale for exploring feature importance and, later, regularization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">y</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">timeseries_train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">plotModelResults</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">X_train</span><span class="o">=</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plotCoefficients</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The test error goes down a little bit. Judging by the coefficients plot, we can say that <code class="docutils literal notranslate"><span class="pre">weekday</span></code> and <code class="docutils literal notranslate"><span class="pre">is_weekend</span></code> are useful features.</p>
</section>
<section id="target-encoding">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Target encoding</a><a class="headerlink" href="#target-encoding" title="Permalink to this heading">#</a></h2>
<p>I’d like to add another variant for encoding categorical variables: encoding by mean value. If it is undesirable to explode a dataset by using many dummy variables that can lead to the loss of information and if they cannot be used as real values because of the conflicts like “0 hours &lt; 23 hours”, then it’s possible to encode a variable with slightly more interpretable values. The natural idea is to encode with the mean value of the target variable. In our example, every day of the week and every hour of the day can be encoded by the corresponding average number of ads watched during that day or hour. It’s very important to make sure that the mean value is calculated over the training set only (or over the current cross-validation fold only) so that the model is not aware of the future.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">code_mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">cat_feature</span><span class="p">,</span> <span class="n">real_feature</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a dictionary where keys are unique categories of the cat_feature,</span>
<span class="sd">    and values are means over real_feature</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">cat_feature</span><span class="p">)[</span><span class="n">real_feature</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at the averages by hour.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">average_hour</span> <span class="o">=</span> <span class="n">code_mean</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Hour averages&quot;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">average_hour</span><span class="p">,</span> <span class="n">orient</span><span class="o">=</span><span class="s2">&quot;index&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, let’s put all the transformations together in a single function .</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepareData</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">lag_start</span><span class="p">,</span> <span class="n">lag_end</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">target_encoding</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        series: pd.DataFrame</span>
<span class="sd">            dataframe with timeseries</span>

<span class="sd">        lag_start: int</span>
<span class="sd">            initial step back in time to slice target variable</span>
<span class="sd">            example - lag_start = 1 means that the model</span>
<span class="sd">                      will see yesterday&#39;s values to predict today</span>

<span class="sd">        lag_end: int</span>
<span class="sd">            final step back in time to slice target variable</span>
<span class="sd">            example - lag_end = 4 means that the model</span>
<span class="sd">                      will see up to 4 days back in time to predict today</span>

<span class="sd">        test_size: float</span>
<span class="sd">            size of the test dataset after train/test split as percentage of dataset</span>

<span class="sd">        target_encoding: boolean</span>
<span class="sd">            if True - add target averages to the dataset</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># copy of the initial dataset</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">series</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
    <span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;y&quot;</span><span class="p">]</span>

    <span class="c1"># lags of series</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lag_start</span><span class="p">,</span> <span class="n">lag_end</span><span class="p">):</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;lag_</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="c1"># datetime features</span>
    <span class="n">data</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;hour&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">hour</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weekday&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">weekday</span>
    <span class="n">data</span><span class="p">[</span><span class="s2">&quot;is_weekend&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">weekday</span><span class="o">.</span><span class="n">isin</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span> <span class="o">*</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">target_encoding</span><span class="p">:</span>
        <span class="c1"># calculate averages on train set only</span>
        <span class="n">test_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">())</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">test_size</span><span class="p">))</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;weekday_average&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">map</span><span class="p">(</span><span class="n">code_mean</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="n">test_index</span><span class="p">],</span> <span class="s2">&quot;weekday&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">weekday</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">data</span><span class="p">[</span><span class="s2">&quot;hour_average&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">map</span><span class="p">(</span><span class="n">code_mean</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="n">test_index</span><span class="p">],</span> <span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">hour</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># drop encoded variables</span>
        <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;hour&quot;</span><span class="p">,</span> <span class="s2">&quot;weekday&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># train-test split</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">y</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;y&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">timeseries_train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span>
    <span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span> <span class="n">lag_start</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">lag_end</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">target_encoding</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">plotModelResults</span><span class="p">(</span>
    <span class="n">lr</span><span class="p">,</span>
    <span class="n">X_train</span><span class="o">=</span><span class="n">X_train_scaled</span><span class="p">,</span>
    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_scaled</span><span class="p">,</span>
    <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plotCoefficients</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We see some <strong>overfitting</strong>! <code class="docutils literal notranslate"><span class="pre">Hour_average</span></code> was so great in the training dataset that the model decided to concentrate all of its forces on it. As a result, the quality of prediction dropped. This problem can be solved in a variety of ways; for example, we can calculate the target encoding not for the whole train set, but for some window instead. That way, encodings from the last observed window will most likely better describe the current series state. Alternatively, we can just drop it manually since we are sure that it makes things only worse in this case.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">prepareData</span><span class="p">(</span>
    <span class="n">ads</span><span class="o">.</span><span class="n">Ads</span><span class="p">,</span> <span class="n">lag_start</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">lag_end</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">target_encoding</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">X_train_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="regularization-and-feature-selection">
<h2><a class="toc-backref" href="#id18" role="doc-backlink">Regularization and feature selection</a><a class="headerlink" href="#regularization-and-feature-selection" title="Permalink to this heading">#</a></h2>
<p>As we already know, not all features are equally healthy – some may lead to overfitting while others should be removed. Besides manual inspection, we can apply regularization. Two of the most popular regression models with regularization are Ridge and Lasso regressions. They both add some more constrains to our loss function.</p>
<p>In the case of Ridge regression, those constraints are the sum of squares of the coefficients multiplied by the regularization coefficient. The bigger the coefficient a feature has, the bigger our loss will be. Hence, we will try to optimize the model while keeping the coefficients fairly low.</p>
<p>As a result of this <span class="math notranslate nohighlight">\(L2\)</span> regularization, we will have higher bias and lower variance, so the model will generalize better (at least that’s what we hope will happen).</p>
<p>The second regression model, Lasso regression, adds to the loss function, not squares, but absolute values of the coefficients. As a result, during the optimization process, coefficients of unimportant features may become zeroes, which allows for automated feature selection. This regularization type is called <span class="math notranslate nohighlight">\(L1\)</span>.</p>
<p>First, let’s make sure that we have features to drop and that the data has highly correlated features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">corr</span><span class="p">());</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LassoCV</span><span class="p">,</span> <span class="n">RidgeCV</span>

<span class="n">ridge</span> <span class="o">=</span> <span class="n">RidgeCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="n">tscv</span><span class="p">)</span>
<span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">plotModelResults</span><span class="p">(</span>
    <span class="n">ridge</span><span class="p">,</span>
    <span class="n">X_train</span><span class="o">=</span><span class="n">X_train_scaled</span><span class="p">,</span>
    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_scaled</span><span class="p">,</span>
    <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plotCoefficients</span><span class="p">(</span><span class="n">ridge</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can clearly see some coefficients are getting closer and closer to zero (though they never actually reach it) as their importance in the model drops.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lasso</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="n">tscv</span><span class="p">)</span>
<span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">plotModelResults</span><span class="p">(</span>
    <span class="n">lasso</span><span class="p">,</span>
    <span class="n">X_train</span><span class="o">=</span><span class="n">X_train_scaled</span><span class="p">,</span>
    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_scaled</span><span class="p">,</span>
    <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plotCoefficients</span><span class="p">(</span><span class="n">lasso</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Lasso regression turned out to be more conservative; it removed 23-rd lag from the most important features and dropped 5 features completely, which only made the quality of prediction better.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="boosting">
<h1><a class="toc-backref" href="#id19" role="doc-backlink">Boosting</a><a class="headerlink" href="#boosting" title="Permalink to this heading">#</a></h1>
<p>Why shouldn’t we try XGBoost now?</p>
<figure class="align-default">
<a class="reference internal image-reference" href="../../_images/xgboost_the_things.jpg"><img alt="../../_images/xgboost_the_things.jpg" src="../../_images/xgboost_the_things.jpg" style="width: 200px;" /></a>
</figure>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>

<span class="n">xgb</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">verbosity</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plotModelResults</span><span class="p">(</span>
    <span class="n">xgb</span><span class="p">,</span>
    <span class="n">X_train</span><span class="o">=</span><span class="n">X_train_scaled</span><span class="p">,</span>
    <span class="n">X_test</span><span class="o">=</span><span class="n">X_test_scaled</span><span class="p">,</span>
    <span class="n">plot_intervals</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">plot_anomalies</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have a winner! This is the smallest error on the test set among all the models we’ve tried so far.</p>
<p>But, this victory is decieving, and it might not be the brightest idea to fit <code class="docutils literal notranslate"><span class="pre">xgboost</span></code> as soon as you get your hands on time series data. Generally, tree-based models handle trends in data poorly when compared with linear models. In that case, you would have to detrend your series first or use some tricks to make the magic happen. Ideally, you can make the series stationary and then use XGBoost. For example, you can forecast trend separately with a linear model and then add predictions from <code class="docutils literal notranslate"><span class="pre">xgboost</span></code> to get a final forecast.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="conclusion">
<h1><a class="toc-backref" href="#id20" role="doc-backlink">Conclusion</a><a class="headerlink" href="#conclusion" title="Permalink to this heading">#</a></h1>
<p>We discussed different time series analysis and prediction methods. Unfortunately, or maybe luckily, there is no one way to solve these kind of problems. Methods developed in the 1960s (and some even in the beginning of the 21st century) are still popular, along with LSTMs and RNNs (not covered in this article). This is partially related to the fact that the prediction task, like any other data-related task, requires creativity in so many aspects and definitely requires research. In spite of the large number of formal quality metrics and approaches to parameters estimation, it is often necessary to try something different for each time series. Last but not least, the balance between quality and cost is important. As a good example, the SARIMA model can produce spectacular results after tuning but can require many hours of <em>tambourine dancing</em> time series manipulation while a simple linear regression model can be built in 10 minutes and can achieve more or less comparable results.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="useful-resources">
<h1><a class="toc-backref" href="#id21" role="doc-backlink">Useful resources</a><a class="headerlink" href="#useful-resources" title="Permalink to this heading">#</a></h1>
<ul class="simple">
<li><p>The same notebook as an interactive web-based <a class="reference external" href="https://www.kaggle.com/kashnitsky/topic-9-part-1-time-series-analysis-in-python">Kaggle Kernel</a></p></li>
<li><p>“LSTM (Long Short Term Memory) Networks for predicting Time Series” - a tutorial by Max Sergei Bulaev within <a class="reference external" href="http://mlcourse.ai">mlcourse.ai</a> (full list of tutorials is <a class="reference external" href="https://mlcourse.ai/tutorials">here</a>)</p></li>
<li><p>Main course <a class="reference external" href="https://mlcourse.ai">site</a>, <a class="reference external" href="https://github.com/Yorko/mlcourse.ai">course repo</a>, and YouTube <a class="reference external" href="https://www.youtube.com/watch?v=QKTuw4PNOsU&amp;list=PLVlY_7IJCMJeRfZ68eVfEcu-UcN9BbwiX">channel</a></p></li>
<li><p>Course materials as a <a class="reference external" href="https://www.kaggle.com/kashnitsky/mlcourse">Kaggle Dataset</a></p></li>
<li><p>Medium <a class="reference external" href="https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-9-time-series-analysis-in-python-a270cb05e0b3?source=collection_home---6------2---------------------">“story”</a> based on this notebook</p></li>
<li><p>If you read Russian: an <a class="reference external" href="https://habr.com/ru/company/ods/blog/327242/">article</a> on <a class="reference external" href="http://Habr.com">Habr.com</a> with ~ the same material. And a <a class="reference external" href="https://youtu.be/_9lBwXnbOd8">lecture</a> on YouTube</p></li>
<li><p><a class="reference external" href="https://people.duke.edu/~rnau/411home.htm">Online textbook</a> for the advanced statistical forecasting course at Duke University - covers various smoothing techniques in detail along with linear and ARIMA models</p></li>
<li><p><a class="reference external" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-15-276">Comparison of ARIMA and Random Forest time series models for prediction of avian influenza H5N1 outbreaks</a> - one of a few cases where using random forest for time series forecasting is actively defended</p></li>
<li><p><a class="reference external" href="http://www.blackarbs.com/blog/time-series-analysis-in-python-linear-models-to-garch/11/1/2016">Time Series Analysis (TSA) in Python - Linear Models to GARCH</a> - applying the ARIMA models family to the task of modeling financial indicators (by Brian Christopher)</p></li>
</ul>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/topic09"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="topic09_intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Topic 9. Time Series Analysis with Python</p>
      </div>
    </a>
    <a class="right-next"
       href="topic9_part2_facebook_prophet.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Topic 9. Time series analysis in Python. Part 2. Predicting the future with Facebook Prophet</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Topic 9. Part 1. Time series analysis in Python</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#article-outline">Article outline</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#forecast-quality-metrics">Forecast quality metrics</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#move-smoothe-evaluate">Move, smoothe, evaluate</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exponential-smoothing">Exponential smoothing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#double-exponential-smoothing">Double exponential smoothing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#triple-exponential-smoothing-a-k-a-holt-winters">Triple exponential smoothing a.k.a. Holt-Winters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-cross-validation">Time series cross validation</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#econometric-approach">Econometric approach</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stationarity">Stationarity</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-rid-of-non-stationarity-and-building-sarima">Getting rid of non-stationarity and building SARIMA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#arima-family-crash-course">ARIMA-family Crash-Course</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-and-not-only-models-for-time-series">Linear (and not only) models for time series</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-extraction">Feature extraction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#time-series-lags">Time series lags</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#target-encoding">Target encoding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization-and-feature-selection">Regularization and feature selection</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#boosting">Boosting</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">Conclusion</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#useful-resources">Useful resources</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Yury Kashnitsky (yorko)
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>